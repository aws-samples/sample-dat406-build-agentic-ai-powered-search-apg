# Lab 1: Building AI-Powered Semantic Search with pgvector and Amazon Bedrock

**Duration**: 20 minutes  
**Level**: 300 (Intermediate)

## ğŸ¯ Learning Objectives

By the end of this lab, you will:
- âœ… Set up Amazon Aurora PostgreSQL with pgvector extension
- âœ… Load product catalog data into Aurora
- âœ… Generate vector embeddings using Amazon Bedrock (Cohere Embed English v3)
- âœ… Create HNSW indexes for fast similarity search
- âœ… Perform semantic search queries using pgvector
- âœ… Understand vector similarity and cosine distance

## ğŸ“‹ Prerequisites

- AWS Account with access to:
  - Amazon Aurora PostgreSQL
  - Amazon Bedrock (Cohere Embed English v3 model enabled)
- Python 3.11+ installed
- Jupyter Notebook environment
- Basic SQL knowledge

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Product Data   â”‚
â”‚  (21,704 items) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Amazon Bedrock  â”‚â—„â”€â”€â”€â”€â”€â”‚  Python Script   â”‚
â”‚ Cohere Embed v3 â”‚      â”‚  (Batch Process) â”‚
â”‚ 1024 dimensions â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Aurora PostgreSQL + pgvector  â”‚
â”‚   â€¢ Vector embeddings (1024d)   â”‚
â”‚   â€¢ HNSW index for fast search  â”‚
â”‚   â€¢ Cosine similarity operator  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Lab Contents

- `Part 1_Building AI-Powered Semantic Product Search with pgvector and Amazon Bedrock (1).ipynb` - Main lab notebook
- Sample product data (loaded from `../data/amazon-products-sample.csv`)

## ğŸš€ Getting Started

### Step 1: Open the Notebook

```bash
cd lab1
jupyter notebook
```

Open: `Part 1_Building AI-Powered Semantic Product Search with pgvector and Amazon Bedrock (1).ipynb`

### Step 2: Configure AWS Credentials

Ensure your AWS credentials are configured:

```bash
aws configure
# OR set environment variables
export AWS_ACCESS_KEY_ID=your_key
export AWS_SECRET_ACCESS_KEY=your_secret
export AWS_REGION=us-west-2
```

### Step 3: Set Database Connection

Update the notebook with your Aurora cluster endpoint:

```python
DB_HOST = "your-aurora-cluster.region.rds.amazonaws.com"
DB_PORT = 5432
DB_NAME = "postgres"
DB_USER = "postgres"
DB_PASSWORD = "your-password"
```

### Step 4: Run Through the Notebook

Follow the notebook cells sequentially:

1. **Setup** - Install dependencies and import libraries
2. **Database Connection** - Connect to Aurora PostgreSQL
3. **Enable pgvector** - Install and configure pgvector extension
4. **Load Data** - Import product catalog (21,704 products)
5. **Generate Embeddings** - Use Bedrock to create vector embeddings
6. **Create Indexes** - Build HNSW index for fast similarity search
7. **Semantic Search** - Query products using natural language
8. **Analysis** - Explore similarity scores and results

## ğŸ” Key Concepts

### Vector Embeddings
- Transform text into 1024-dimensional vectors
- Capture semantic meaning of product descriptions
- Enable similarity-based search

### pgvector Extension
- PostgreSQL extension for vector operations
- Supports cosine distance (`<=>` operator)
- HNSW index for approximate nearest neighbor search

### HNSW Index
- Hierarchical Navigable Small World graphs
- Fast approximate similarity search
- Sub-100ms query times on 21K+ products

### Similarity Scoring
- Cosine similarity: 1 - (embedding1 <=> embedding2)
- Scores range from 0 (dissimilar) to 1 (identical)
- Typical relevant results: 60%+ similarity

## ğŸ“Š Expected Results

After completing this lab:
- âœ… 21,704 products loaded with embeddings
- âœ… HNSW index created (m=16, ef_construction=64)
- âœ… Semantic search queries return relevant results
- âœ… Query latency: 50-150ms average

## ğŸ“ Sample Queries

```sql
-- Find wireless headphones
SELECT product_description, price, stars, 
       1 - (embedding <=> query_embedding) as similarity
FROM bedrock_integration.product_catalog
WHERE 1 - (embedding <=> query_embedding) > 0.6
ORDER BY embedding <=> query_embedding
LIMIT 10;

-- Find laptops under $1000
SELECT product_description, price, stars,
       1 - (embedding <=> query_embedding) as similarity
FROM bedrock_integration.product_catalog
WHERE price < 1000 
  AND 1 - (embedding <=> query_embedding) > 0.6
ORDER BY embedding <=> query_embedding
LIMIT 10;
```

## ğŸ› Troubleshooting

### Issue: Bedrock Access Denied
**Solution**: Enable Cohere Embed English v3 model in Bedrock console

### Issue: pgvector Extension Not Found
**Solution**: Ensure Aurora PostgreSQL version supports pgvector (15.3+)

### Issue: Slow Embedding Generation
**Solution**: Use batch processing (100 products per batch) as shown in notebook

### Issue: Low Similarity Scores
**Solution**: Adjust `min_similarity` threshold (try 0.5 or 0.4)

## ğŸ“š Additional Resources

- [pgvector Documentation](https://github.com/pgvector/pgvector)
- [Amazon Bedrock User Guide](https://docs.aws.amazon.com/bedrock/)
- [Aurora PostgreSQL Documentation](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/)

## â­ï¸ Next Steps

After completing Lab 1, proceed to **Lab 2** to build the full Blaize Bazaar application with:
- FastAPI backend with semantic search API
- React frontend with AI chat assistant
- Multi-agent system with MCP integration
- Real-time product recommendations

---

**Questions?** Open an issue or ask your workshop instructor.
